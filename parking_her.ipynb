{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eeje4O8fviH",
        "pycharm": {
          "name": "#%% md\n"
        }
      },
      "source": [
        "# Parking with Hindsight Experience Replay\n",
        "\n",
        "##  Warming up\n",
        "We start with a few useful installs and imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bzMSuJEOfviP",
        "pycharm": {
          "is_executing": false,
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#@title Install environment and agent\n",
        "# !pip install highway-env\n",
        "# TODO: we use the bleeding edge version because the current stable version does not support the latest gym>=0.21 versions. Revert back to stable at the next SB3 release.\n",
        "# !pip install git+https://github.com/DLR-RM/stable-baselines3\n",
        "\n",
        "# Environment\n",
        "import gymnasium as gym\n",
        "\n",
        "# Agent\n",
        "from stable_baselines3 import HerReplayBuffer, SAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "so7yH4ucyB-3"
      },
      "outputs": [],
      "source": [
        "#@title Import helpers for visualization of episodes\n",
        "import sys\n",
        "from tqdm.auto import trange\n",
        "# !pip install tensorboardx gym pyvirtualdisplay\n",
        "# !apt-get install -y xvfb ffmpeg\n",
        "# !git clone https://github.com/Farama-Foundation/HighwayEnv.git 2> /dev/null\n",
        "sys.path.insert(0, '/Users/anmol/githubRepos/CS269-Parking/scripts')\n",
        "import highway_env\n",
        "\n",
        "from utils import record_videos, show_videos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "frgfxpsP3fFn"
      },
      "outputs": [],
      "source": [
        "#@title Tensorboard - click the refresh button once training is running\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from highway_env.vehicle.kinematics import Vehicle\n",
        "print(\"highway_env module file:\", highway_env.__file__)\n",
        "print(\"Vehicle.MAX_SPEED:\", Vehicle.MAX_SPEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Full configuration dictionary for environment\n",
        "import numpy as np\n",
        "parking_config = {\n",
        "    # Observation configuration\n",
        "    \"observation\": {\n",
        "        \"type\": \"KinematicsGoal\",\n",
        "        \"features\": [\"x\", \"y\", \"vx\", \"vy\", \"cos_h\", \"sin_h\"],\n",
        "        \"scales\": [100, 100, 5, 5, 1, 1],\n",
        "        \"normalize\": False,\n",
        "    },\n",
        "    \n",
        "    # Action configuration\n",
        "    \"action\": {\n",
        "        \"type\": \"ContinuousAction\",\n",
        "        \"acceleration_range\": (-2, 2),\n",
        "        \"speed_range\": (-5, 5),\n",
        "    },\n",
        "    \n",
        "    # Reward parameters\n",
        "    \"reward_weights\": [1, 0.5, 0.01, 0.01, 1, 1],  # Weights for [x, y, vx, vy, cos_h, sin_h]\n",
        "    \"success_goal_reward\": 0.15,\n",
        "    \"collision_reward\": -5,\n",
        "    \n",
        "    # Vehicle control parameters\n",
        "    \"steering_range\": np.deg2rad(60),  # Maximum steering angle in radians\n",
        "    \n",
        "    # Simulation parameters\n",
        "    \"simulation_frequency\": 15,  # Hz\n",
        "    \"policy_frequency\": 5,       # Hz\n",
        "    \"duration\": 40,             # Maximum episode duration in steps\n",
        "    \n",
        "    # Rendering parameters\n",
        "    \"screen_width\": 600,\n",
        "    \"screen_height\": 300,\n",
        "    \"centering_position\": [0.5, 0.5],\n",
        "    \"scaling\": 7,\n",
        "    \"show_trajectories\": True,\n",
        "    \n",
        "    # Environment setup\n",
        "    \"controlled_vehicles\": 1,    # Number of vehicles to control\n",
        "    \"vehicles_count\": 12,         # Number of parked vehicles (obstacles)\n",
        "    \"add_walls\": True,           # Whether to add boundary walls\n",
        "\n",
        "    # Additional parameters from AbstractEnv\n",
        "    \"offscreen_rendering\": False,\n",
        "    \"manual_control\": False,\n",
        "    \"real_time_rendering\": False,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = gym.make(\"parking-v0\", render_mode=\"rgb_array\", config=parking_config)\n",
        "env = record_videos(env)\n",
        "env.reset()\n",
        "done = False\n",
        "while not done:\n",
        "    action = env.action_space.sample()\n",
        "    obs, reward, done, truncated, info = env.step(action)\n",
        "env.close()\n",
        "show_videos()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Y5TOvonYqP-g",
        "pycharm": {
          "name": "#%% \n"
        }
      },
      "outputs": [],
      "source": [
        "#@title Training\n",
        "\n",
        "LEARNING_STEPS = 1e6 # @param {type: \"number\"}\n",
        "env = gym.make('parking-v0', config=parking_config)\n",
        "her_kwargs = dict(n_sampled_goal=4, goal_selection_strategy='future')\n",
        "# model = SAC('MultiInputPolicy', env, replay_buffer_class=HerReplayBuffer,\n",
        "#             replay_buffer_kwargs=her_kwargs, verbose=1, \n",
        "#             tensorboard_log=\"logs\", \n",
        "#             buffer_size=int(1e6),\n",
        "#             learning_rate=1e-3,\n",
        "#             gamma=0.95, batch_size=1024, tau=0.05,\n",
        "#             policy_kwargs=dict(net_arch=[512, 512, 512]),\n",
        "#             learning_starts=1000,\n",
        "#             )\n",
        "\n",
        "model = SAC.load(\"/Users/anmol/githubRepos/CS269-Parking/scripts/model_20251129_005021_herRevParkEmpty.zip\",env=env)\n",
        "model.learning_starts = 10000\n",
        "model.learn(int(LEARNING_STEPS))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model = SAC.load(\"/Users/anmol/githubRepos/CS269-Parking/scripts/model_20251129_005021_herRevParkEmpty.zip\",env=env)\n",
        "# loaded params\n",
        "# print(model.learning_rate)\n",
        "# print(model.gamma)\n",
        "# print(model.batch_size)\n",
        "# print(model.tau)\n",
        "# print(model.train_freq)\n",
        "# print(model.policy_kwargs)\n",
        "\n",
        "# updating params\n",
        "# model.learning_rate = 3e-4\n",
        "# model.gamma = 0.98\n",
        "# model.batch_size = 1024\n",
        "# model.tau = 0.05\n",
        "\n",
        "# updated params\n",
        "# print(model.learning_rate)\n",
        "# print(model.gamma)\n",
        "# print(model.batch_size)\n",
        "# print(model.tau)\n",
        "# print(model.train_freq)\n",
        "# print(model.policy_kwargs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "xOcOP7Of18T2",
        "pycharm": {
          "name": "#%%\n"
        }
      },
      "outputs": [],
      "source": [
        "#@title Visualize a few episodes\n",
        "from tqdm.auto import trange\n",
        "\n",
        "N_EPISODES = 10  # @param {type: \"integer\"}\n",
        "\n",
        "env = gym.make('parking-v0', render_mode='rgb_array')\n",
        "env = record_videos(env)\n",
        "for episode in trange(N_EPISODES, desc=\"Test episodes\"):\n",
        "    obs, info = env.reset()\n",
        "    done = truncated = False\n",
        "    while not (done or truncated):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, done, truncated, info = env.step(action)\n",
        "env.close()\n",
        "show_videos()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "parking_her.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
